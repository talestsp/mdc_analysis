{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI Categories - Google Places to Ontology System Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir /home/tales/dev/master/mdc_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/tales/dev/master/mdc_analysis/\")\n",
    "print(\"working dir\", os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from src.dao import csv_dao\n",
    "from src.entity.stop_region import StopRegionGroup\n",
    "from src.poi_grabber import google_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words_from_list(lista, words_to_remove=[\"establishment\", \"point_of_interest\"]):\n",
    "    for word_to_remove in words_to_remove:\n",
    "        if word_to_remove in lista:\n",
    "            lista.remove(word_to_remove)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChIJTcpEIDQujEcRfRIRizbvj4k</th>\n",
       "      <td>Office d'impôt des districts de Lausanne et Ou...</td>\n",
       "      <td>[accounting, finance, point_of_interest, local...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChIJPV-d_9dkjEcRh-AFXijs5H0</th>\n",
       "      <td>Graphiste Imprimeur Genève Agence BESTRIBUTION</td>\n",
       "      <td>[store, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChIJ6TtT3J1EjEcRdmsz6L2gHTU</th>\n",
       "      <td>institut beauté lys</td>\n",
       "      <td>[beauty_salon, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChIJLZi4AC8ujEcRvSGJiRYVAk0</th>\n",
       "      <td>cabinet evexia | coaching &amp; soins thérapeutiques</td>\n",
       "      <td>[health, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChIJKTbDs6ygmkcRhp_reVwKcjc</th>\n",
       "      <td>RTM Financial Coaching AG</td>\n",
       "      <td>[finance, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          name  \\\n",
       "place_id                                                                         \n",
       "ChIJTcpEIDQujEcRfRIRizbvj4k  Office d'impôt des districts de Lausanne et Ou...   \n",
       "ChIJPV-d_9dkjEcRh-AFXijs5H0     Graphiste Imprimeur Genève Agence BESTRIBUTION   \n",
       "ChIJ6TtT3J1EjEcRdmsz6L2gHTU                                institut beauté lys   \n",
       "ChIJLZi4AC8ujEcRvSGJiRYVAk0   cabinet evexia | coaching & soins thérapeutiques   \n",
       "ChIJKTbDs6ygmkcRhp_reVwKcjc                          RTM Financial Coaching AG   \n",
       "\n",
       "                                                                         types  \n",
       "place_id                                                                        \n",
       "ChIJTcpEIDQujEcRfRIRizbvj4k  [accounting, finance, point_of_interest, local...  \n",
       "ChIJPV-d_9dkjEcRh-AFXijs5H0          [store, point_of_interest, establishment]  \n",
       "ChIJ6TtT3J1EjEcRdmsz6L2gHTU   [beauty_salon, point_of_interest, establishment]  \n",
       "ChIJLZi4AC8ujEcRvSGJiRYVAk0         [health, point_of_interest, establishment]  \n",
       "ChIJKTbDs6ygmkcRhp_reVwKcjc        [finance, point_of_interest, establishment]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pois = google_places.load_all_google_places_data(valid_pois=True)\n",
    "pois_lite = all_pois[[\"name\", \"types\"]]\n",
    "pois_lite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All visited POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user 6189 data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tales/dev/master/mdc_analysis/src/entity/stop_region.py:69: FutureWarning: 'place_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  self.close_pois = google_places.load_all_google_places_data(valid_pois=True).merge(pois, on=\"place_id\", how=\"inner\").sort_values(by=\"distance\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user 5936 data\n",
      "Loading user 6087 data\n",
      "Loading user 5973 data\n",
      "Loading user 6085 data\n",
      "Loading user 6074 data\n",
      "Loading user 6012 data\n",
      "Loading user 5982 data\n",
      "Loading user 5948 data\n",
      "Loading user 5974 data\n",
      "Loading user 6090 data\n",
      "Loading user 6199 data\n",
      "Loading user 6068 data\n",
      "Loading user 6024 data\n",
      "Loading user 5976 data\n",
      "Loading user 6094 data\n",
      "Loading user 5941 data\n",
      "Loading user 5995 data\n",
      "Loading user 5962 data\n",
      "Loading user 6093 data\n",
      "Loading user 6033 data\n",
      "Loading user 6079 data\n",
      "Loading user 6038 data\n",
      "Loading user 6175 data\n",
      "Loading user 6042 data\n",
      "Loading user 5924 data\n",
      "Loading user 6083 data\n",
      "Loading user 6178 data\n",
      "Loading user 5958 data\n",
      "Loading user 6086 data\n",
      "Loading user 6100 data\n",
      "Loading user 5945 data\n",
      "Loading user 5925 data\n",
      "Loading user 5935 data\n",
      "Loading user 6172 data\n",
      "Loading user 5955 data\n",
      "Loading user 6073 data\n",
      "Loading user 5980 data\n",
      "Loading user 6010 data\n",
      "Loading user 5993 data\n",
      "Loading user 6037 data\n",
      "Loading user 5979 data\n",
      "Loading user 5966 data\n",
      "Loading user 5985 data\n",
      "Loading user 5967 data\n",
      "Loading user 5970 data\n",
      "Loading user 6169 data\n",
      "Loading user 6188 data\n",
      "Loading user 6097 data\n",
      "Loading user 6096 data\n",
      "Loading user 6041 data\n",
      "Loading user 6192 data\n",
      "Loading user 6064 data\n",
      "Loading user 6183 data\n",
      "Loading user 5954 data\n",
      "Loading user 5972 data\n",
      "Loading user 6060 data\n",
      "Loading user 6069 data\n",
      "Loading user 5937 data\n",
      "Loading user 6028 data\n",
      "Loading user 5990 data\n",
      "Loading user 6071 data\n",
      "Loading user 5928 data\n",
      "Loading user 5992 data\n",
      "Loading user 6058 data\n",
      "Loading user 6001 data\n",
      "Loading user 5964 data\n",
      "Loading user 5950 data\n",
      "Loading user 5991 data\n",
      "Loading user 6177 data\n",
      "Loading user 5961 data\n",
      "Loading user 6176 data\n",
      "Loading user 6007 data\n",
      "Loading user 5956 data\n",
      "Loading user 6182 data\n",
      "Loading user 6171 data\n",
      "Loading user 5938 data\n",
      "Loading user 5960 data\n",
      "Loading user 6103 data\n",
      "Loading user 6179 data\n",
      "Loading user 6027 data\n",
      "Loading user 5947 data\n",
      "Loading user 6020 data\n",
      "Loading user 5927 data\n",
      "Loading user 6047 data\n",
      "Loading user 6072 data\n",
      "Loading user 5977 data\n",
      "Loading user 6198 data\n",
      "Loading user 5957 data\n",
      "Loading user 5975 data\n",
      "Loading user 6057 data\n",
      "Loading user 6102 data\n",
      "Loading user 6043 data\n",
      "Loading user 6077 data\n",
      "Loading user 6026 data\n",
      "Loading user 6014 data\n",
      "Loading user 6078 data\n",
      "Loading user 6166 data\n",
      "Loading user 6015 data\n",
      "Loading user 5978 data\n",
      "Loading user 5986 data\n",
      "Loading user 5969 data\n",
      "Loading user 6174 data\n",
      "Loading user 5949 data\n",
      "Loading user 5959 data\n",
      "Loading user 6023 data\n",
      "Loading user 6051 data\n",
      "Loading user 6029 data\n",
      "Loading user 6036 data\n",
      "Loading user 6070 data\n",
      "Loading user 5952 data\n",
      "Loading user 6062 data\n",
      "Loading user 6056 data\n",
      "Loading user 5942 data\n",
      "Loading user 5953 data\n",
      "Loading user 6034 data\n",
      "Loading user 6076 data\n",
      "Loading user 6066 data\n",
      "Loading user 5940 data\n",
      "Loading user 6197 data\n",
      "Loading user 6109 data\n",
      "Loading user 6002 data\n",
      "Loading user 6016 data\n",
      "Loading user 6187 data\n",
      "Loading user 5987 data\n",
      "Loading user 6053 data\n",
      "Loading user 6104 data\n",
      "Loading user 5943 data\n",
      "Loading user 6017 data\n",
      "Loading user 6168 data\n",
      "Loading user 6045 data\n",
      "Loading user 5989 data\n",
      "Loading user 5963 data\n",
      "Loading user 5968 data\n",
      "Loading user 6194 data\n",
      "Loading user 6190 data\n",
      "Loading user 6003 data\n",
      "Loading user 6035 data\n",
      "Loading user 6167 data\n",
      "Loading user 6004 data\n",
      "Loading user 6030 data\n",
      "Loading user 6054 data\n",
      "Loading user 6032 data\n",
      "Loading user 6170 data\n",
      "Loading user 6063 data\n",
      "Loading user 6005 data\n",
      "Loading user 5988 data\n",
      "Loading user 5944 data\n",
      "Loading user 6075 data\n",
      "Loading user 6061 data\n",
      "Loading user 5965 data\n",
      "Loading user 6040 data\n",
      "Loading user 6000 data\n",
      "Loading user 6059 data\n",
      "Loading user 5951 data\n",
      "Loading user 6106 data\n",
      "Loading user 6082 data\n",
      "Loading user 6031 data\n",
      "Loading user 6180 data\n",
      "Loading user 6039 data\n",
      "Loading user 6181 data\n",
      "Loading user 6067 data\n",
      "Loading user 5939 data\n"
     ]
    }
   ],
   "source": [
    "users_sr = {}\n",
    "\n",
    "users = os.listdir(\"outputs/stop_regions/\")\n",
    "\n",
    "for user_id in users:\n",
    "    print(\"Loading user {} data\".format(user_id))\n",
    "    users_sr[user_id] = StopRegionGroup(csv_dao.stop_region_sequence(user_id), \n",
    "                                                    agglutinate_stop_regions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Ontology Category System Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../poi_catogories/data/categ_map.json', \"r\") as json_file:\n",
    "    categ_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_types(google_poi):\n",
    "    print(\"Name:\", google_poi[\"name\"])\n",
    "    google_types = remove_words_from_list(google_poi[\"types\"])\n",
    "    print(\"Types:\", google_poi[\"types\"])\n",
    "    print()\n",
    "    for a_type in google_types:\n",
    "        print(\">>>\", categ_map[a_type])\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Office d'impôt des districts de Lausanne et Ouest Lausannois\n",
      "Types: ['accounting', 'finance', 'local_government_office']\n",
      "\n",
      ">>> ['Business buildings', 'Companies & Enterprises', 'Financial and insurance']\n",
      ">>> ['Business buildings', 'Companies & Enterprises', 'Financial and insurance']\n",
      ">>> ['Government &  social groups']\n",
      "-----------\n",
      "\n",
      "Name: Graphiste Imprimeur Genève Agence BESTRIBUTION\n",
      "Types: ['store']\n",
      "\n",
      ">>> ['Business buildings', 'Companies & Enterprises', 'Shopping']\n",
      "-----------\n",
      "\n",
      "Name: institut beauté lys\n",
      "Types: ['beauty_salon']\n",
      "\n",
      ">>> ['Life service']\n",
      "-----------\n",
      "\n",
      "Name: cabinet evexia | coaching & soins thérapeutiques\n",
      "Types: ['health']\n",
      "\n",
      ">>> ['Medical Care']\n",
      "-----------\n",
      "\n",
      "Name: RTM Financial Coaching AG\n",
      "Types: ['finance']\n",
      "\n",
      ">>> ['Business buildings', 'Companies & Enterprises', 'Financial and insurance']\n",
      "-----------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "place_id\n",
       "ChIJTcpEIDQujEcRfRIRizbvj4k    None\n",
       "ChIJPV-d_9dkjEcRh-AFXijs5H0    None\n",
       "ChIJ6TtT3J1EjEcRdmsz6L2gHTU    None\n",
       "ChIJLZi4AC8ujEcRvSGJiRYVAk0    None\n",
       "ChIJKTbDs6ygmkcRhp_reVwKcjc    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_lite.head().apply(map_types, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list = pd.Series(d[\"types\"].sum())\n",
    "types_list = types_list[(types_list != \"establishment\") & (types_list != \"point_of_interest\")]\n",
    "types_list = types_list.apply(lambda value : pd.Series(value).drop_duplicates().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15,5))\n",
    "types_list.astype(str).value_counts().head(35).plot.bar(title=\"Frequency of POI types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"types\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"types\"].apply(len).plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of similar places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d[\"name\"] == \"McDonald’s\"][\"types\"].astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_list_index(term, lista):\n",
    "    if term in lista:\n",
    "        return lista.index(term)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def term_index_len(term, types_series):\n",
    "    term_index = types_series.apply(lambda lista : term_list_index(term, lista))\n",
    "    term_types_len = types_series.apply(lambda lista : len(lista))\n",
    "\n",
    "    return pd.DataFrame({\"index\": term_index, \"len\": term_types_len})\n",
    "\n",
    "def left_right_term(term, types_series):\n",
    "    lefts = []\n",
    "    rights = []\n",
    "\n",
    "    term_index_len_df = term_index_len(term, types_series)\n",
    "\n",
    "    for type_row in types_series.loc[term_index_len_df[term_index_len_df[\"index\"] >= 0].index]:\n",
    "        left = type_row[0:type_row.index(term)]\n",
    "        lefts = lefts + left\n",
    "        right = type_row[type_row.index(term) + 1:]\n",
    "        rights = rights + right\n",
    "\n",
    "    lefts = pd.Series(lefts).rename({0: \"left\"})\n",
    "    rights = pd.Series(rights).rename({0: \"right\"})\n",
    "\n",
    "    lr = lefts.value_counts().to_frame().merge(rights.value_counts().to_frame(), how=\"outer\",\n",
    "                                                 left_index=True,\n",
    "                                                 right_index=True)\n",
    "    \n",
    "    return lr.sort_values(by=[\"0_x\", \"0_y\"], ascending=False).rename({\"0_x\": \"left\", \"0_y\": \"right\"}, axis=1)\n",
    "\n",
    "def term_placement_analisis(lr, show=True):\n",
    "    right = lr[(lr[\"left\"].isna()) & (~lr[\"right\"].isna())]\n",
    "    left = lr[(lr[\"right\"].isna()) & (~lr[\"left\"].isna())]\n",
    "    both_valid = lr[~(lr[\"right\"].isna()) & (~lr[\"left\"].isna())]\n",
    "    both_nan = lr[(lr[\"right\"].isna()) & (lr[\"left\"].isna())]\n",
    "    \n",
    "    if show:\n",
    "    \n",
    "        print(\"RIGHT side occurrences\")\n",
    "        print()\n",
    "        print(right)\n",
    "        print(\"---\")\n",
    "        print()\n",
    "        print(\"LEFT side occurrences\")\n",
    "        print(left)\n",
    "        print(\"---\")\n",
    "        print()\n",
    "        print(\"BOTH sides occurrences\")\n",
    "        print(both_valid)\n",
    "        print(\"---\")\n",
    "        print()\n",
    "    return {\"right\": right, \"left\": left, \"both\": both_valid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for hierarchy patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = d[\"types\"].apply(lambda lista : \"health\" in lista).value_counts()\n",
    "print(\"'health' happens in {:10.2f}% of cases\".format(n_cases[True] * 100 / n_cases.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_list_index(term, lista):\n",
    "    if term in lista:\n",
    "        return lista.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_index = d[\"types\"].apply(lambda lista : term_list_index('health', lista))\n",
    "health_types_len = d[\"types\"].apply(lambda lista : len(lista))\n",
    "\n",
    "health = pd.DataFrame({\"index\": health_index, \"len\": health_types_len})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index occurrence in types list and types list length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health[health[\"index\"] >= 0].sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health[health[\"index\"] >= 0].plot.scatter(\"len\", \"index\", title=\"'health' term index vs types_list length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health.loc[health[(health[\"len\"] >= 8) & (health[\"index\"] >= 0)].index].sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_lr = left_right_term('health', d[\"types\"])\n",
    "lr = term_placement_analisis(health_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### left vs right: term ocurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_types_list = pd.Series(types.sum()).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types_list = pd.Series(types.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types_list[(types_list != 'establishment') & (types_list != 'point_of_interest')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term = unique_types_list.sample().item()\n",
    "# term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"school\"\n",
    "\n",
    "print(\"Occurrences for term: {}\".format(term))\n",
    "print(\"\\n\\n\")\n",
    "lr_health = left_right_term(term, d[\"types\"])\n",
    "lr = term_placement_analisis(lr_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"bar\"\n",
    "\n",
    "print(\"Occurrences for term: {}\".format(term))\n",
    "print(\"\\n\\n\")\n",
    "lr_health = left_right_term(term, d[\"types\"])\n",
    "lr = term_placement_analisis(lr_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"store\"\n",
    "\n",
    "print(\"Occurrences for term: {}\".format(term))\n",
    "print(\"\\n\\n\")\n",
    "lr_health = left_right_term(term, d[\"types\"])\n",
    "lr = term_placement_analisis(lr_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"hair_care\"\n",
    "\n",
    "print(\"Occurrences for term: {}\".format(term))\n",
    "print(\"\\n\\n\")\n",
    "lr_health = left_right_term(term, d[\"types\"])\n",
    "lr = term_placement_analisis(lr_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"natural_feature\"\n",
    "\n",
    "print(\"Occurrences for term: {}\".format(term))\n",
    "print(\"\\n\\n\")\n",
    "lr_health = left_right_term(term, d[\"types\"])\n",
    "lr = term_placement_analisis(lr_health)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type popularity vs right / left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list_freq = types_list[(types_list != 'establishment') & (types_list != 'point_of_interest')].value_counts()\n",
    "types_list_freq = types_list_freq.to_frame().rename(columns={0: \"freq_index\"})\n",
    "types_list_freq = types_list_freq.sort_values(by=\"freq_index\", ascending=False).reset_index().rename(columns={\"index\": \"term\"}).reset_index()\n",
    "types_list_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prop = []\n",
    "\n",
    "for term in types_list_freq[\"term\"]:\n",
    "    lr = term_placement_analisis(left_right_term(term, d[\"types\"]), show=False)\n",
    "    r_prop.append({\"term\": term, \"r_prop\": len(lr[\"right\"]) / (len(lr[\"left\"]) + len(lr[\"right\"]))})\n",
    "    \n",
    "r_prop = pd.DataFrame(r_prop).sort_values(by=\"r_prop\", ascending=False)\n",
    "r_prop = r_prop.sort_values(by=\"r_prop\", ascending=False).reset_index(drop=True).reset_index()\n",
    "r_prop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prop_vs_freq_index = r_prop.merge(types_list_freq, left_on=\"term\", right_on=\"term\", how=\"inner\").rename(columns={\"index_x\": \"index_r_prop\", \"index_y\": \"index_freq\"})\n",
    "r_prop_vs_freq_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prop_vs_freq_index[\"index_r_prop\"].corr(r_prop_vs_freq_index[\"index_freq\"], method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prop_vs_freq_index.plot.scatter(x=\"index_r_prop\", y=\"index_freq\", title=\"Scatter plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more frequent the term is, the less right side elements it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analising leftmosts categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words_from_list(lista, words_to_remove=[\"establishment\", \"point_of_interest\"]):\n",
    "    for word_to_remove in words_to_remove:\n",
    "        if word_to_remove in lista:\n",
    "            lista.remove(word_to_remove)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_types = d[\"types\"].apply(lambda value : remove_words_from_list(value))\n",
    "leftmost = clean_types[clean_types.astype(str) != \"[]\"].apply(lambda value : value[-1])\n",
    "\n",
    "print(len(leftmost.drop_duplicates()), \"leftmost categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Ontology-based category system</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list_unique = pd.Series(types_list).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(types_list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(lista):\n",
    "    num_dict = {}\n",
    "    for i in range(len(lista)):\n",
    "        num_dict[str(i)] = lista[i]\n",
    "    return num_dict\n",
    "\n",
    "def pretty_print_categ_dict(categ_dict):\n",
    "    for key in range(len(categ_dict.keys())):\n",
    "        print(\"{}: {}\".format(key, categ_dict[str(key)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../poi_catogories/data/poi_categories.json', 'r') as json_file:\n",
    "    categories = sorted(json.load(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_dict = to_dict(categories)\n",
    "categ_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Types Categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for a_type in types_list_unique:\n",
    "#     pretty_print_categ_dict(categ_dict)\n",
    "#     print()\n",
    "#     print(\">>> {}\".format(a_type))\n",
    "#     if a_type in categ_map.keys():\n",
    "#         pass\n",
    "    \n",
    "#     else:\n",
    "#         categ_keys = input(\"\").split(\",\")\n",
    "        \n",
    "#         if categ_keys == ['']:\n",
    "#             categ_values = \"\"\n",
    "#         else:\n",
    "#             categ_values = []\n",
    "#             for categ_key in categ_keys:\n",
    "#                 categ_values.append(categ_dict[categ_key])\n",
    "\n",
    "#         categ_map[a_type] = categ_values\n",
    "#     print(a_type, \">>>\", categ_map[a_type])\n",
    "#     print()\n",
    "#     print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../poi_catogories/data/categ_map.json', 'w') as outfile:\n",
    "#     json.dump(categ_map, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../poi_catogories/data/categ_map.json', \"r\") as json_file:\n",
    "    categ_map = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(a_dict, keys_colname, values_colname):\n",
    "    rows = []\n",
    "    for key in a_dict.keys():\n",
    "        rows.append({keys_colname: key, values_colname: a_dict[key]})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_df = dict_to_df(categ_map, \"google_type\", \"new_types\")\n",
    "categ_df.to_csv('../poi_catogories/data/categ_map.csv', index=False)\n",
    "categ_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Ontology-based category system - Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_new_types(categ_df):\n",
    "    expanded_rows = []\n",
    "    \n",
    "    for index, type_row in categ_df.iterrows():\n",
    "        if len(type_row[\"new_types\"]) == 0:\n",
    "            expanded_rows.append({\"google_type\": type_row[\"google_type\"],\n",
    "                                  \"new_type\": \"\"})\n",
    "            \n",
    "        else:\n",
    "            for new_type in type_row[\"new_types\"]:\n",
    "                expanded_rows.append({\"google_type\": type_row[\"google_type\"],\n",
    "                                      \"new_type\": new_type})\n",
    "    \n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "expanded_categ_df = expand_new_types(categ_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Empty Categories</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_categ_df[expanded_categ_df[\"new_type\"] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
