{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.3, 0.1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startprob = np.array([0.6, 0.3, 0.1])\n",
    "startprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7, 0.2, 0.1],\n",
       "       [0.3, 0.5, 0.2],\n",
       "       [0.3, 0.3, 0.4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transmat = np.array([[0.7, 0.2, 0.1], [0.3, 0.5, 0.2], [0.3, 0.3, 0.4]])\n",
    "transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 3., -3.],\n",
       "       [ 5., 10.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.array([[0.0, 0.0], [3.0, -3.0], [5.0, 10.0]])\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars = np.tile(np.identity(2), (3, 1, 1))\n",
    "covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars\n",
    "X, Z = model.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.47982837e-01, -6.03137735e-01],\n",
       "       [ 3.75544866e+00, -2.63403159e+00],\n",
       "       [ 2.03964686e+00, -1.58816463e+00],\n",
       "       [ 3.90972710e+00, -2.68277761e+00],\n",
       "       [ 3.98445451e+00,  1.04216804e+01],\n",
       "       [ 6.17910867e+00,  8.56266823e+00],\n",
       "       [ 6.54424581e+00,  1.12030935e+01],\n",
       "       [-3.33701827e-01,  1.49177739e+00],\n",
       "       [ 4.61924499e+00,  1.06688501e+01],\n",
       "       [-1.80490785e+00, -9.00955401e-01],\n",
       "       [-6.54285072e-01,  4.13218656e-02],\n",
       "       [ 4.54357866e+00, -1.44062771e+00],\n",
       "       [ 2.32553079e+00, -3.49388364e+00],\n",
       "       [ 2.32200665e+00, -2.65079885e+00],\n",
       "       [ 4.22209070e+00, -3.40217120e+00],\n",
       "       [-4.10185368e-03,  8.04470900e-01],\n",
       "       [-1.75242540e+00, -1.46338628e-01],\n",
       "       [ 4.57597383e+00,  1.13827055e+01],\n",
       "       [ 6.25956191e+00,  1.00522609e+01],\n",
       "       [ 7.74394867e-01,  7.28045067e-01],\n",
       "       [ 1.05017427e+00, -3.15573596e-02],\n",
       "       [-2.39055312e-01,  1.72889175e-01],\n",
       "       [ 1.26982518e+00, -3.43627806e+00],\n",
       "       [ 4.44933580e+00, -2.10392554e+00],\n",
       "       [ 3.01721253e+00, -1.99332471e+00],\n",
       "       [ 6.26190743e+00,  1.03415540e+01],\n",
       "       [ 3.99782416e+00,  1.02826466e+01],\n",
       "       [ 5.61171692e+00,  1.11545793e+01],\n",
       "       [ 6.32759914e+00,  9.39797275e+00],\n",
       "       [-8.90124608e-01,  5.27884185e-01],\n",
       "       [ 6.18631734e-01,  1.35802988e-01],\n",
       "       [ 1.79174987e+00,  5.21887719e-01],\n",
       "       [ 2.21911455e-01,  4.46884567e-01],\n",
       "       [-1.00424219e+00,  3.48344579e-01],\n",
       "       [ 3.91417889e+00,  1.19524269e+01],\n",
       "       [ 1.02548705e+00,  2.78913165e-01],\n",
       "       [-2.48815968e-01,  5.81417225e-01],\n",
       "       [ 2.42148466e+00, -2.87302989e+00],\n",
       "       [ 3.00816145e+00,  1.00032518e+01],\n",
       "       [ 3.09349903e+00, -2.80226612e+00],\n",
       "       [-1.21370451e+00, -2.35473607e-01],\n",
       "       [ 1.52308140e+00, -3.56916562e-02],\n",
       "       [ 2.69465943e-01,  8.65609100e-01],\n",
       "       [-7.10476200e-01,  6.76084410e-02],\n",
       "       [ 2.71426623e+00, -2.52786785e+00],\n",
       "       [ 2.70911328e+00, -3.14181558e+00],\n",
       "       [ 3.70898968e-01,  1.08382039e+00],\n",
       "       [-5.86477347e-01, -5.75602013e-01],\n",
       "       [-4.39082934e-01,  4.61159238e-01],\n",
       "       [-2.96800902e-01, -1.17603107e-01],\n",
       "       [ 4.96487974e-01,  1.11940309e+00],\n",
       "       [-8.96379358e-01,  4.79208291e-01],\n",
       "       [ 1.17027298e+00, -4.25732544e-01],\n",
       "       [ 9.53403803e-01,  3.92537724e-01],\n",
       "       [ 3.87803511e-01,  4.14951137e-01],\n",
       "       [-1.89180758e-01,  7.36772819e-01],\n",
       "       [ 3.67201081e+00, -3.45244210e+00],\n",
       "       [ 3.36105772e+00, -4.76674776e+00],\n",
       "       [ 1.65255037e+00, -2.73139245e+00],\n",
       "       [-2.26564036e-01, -8.34565512e-01],\n",
       "       [-9.71455232e-01,  9.01469714e-01],\n",
       "       [-5.49339342e-01, -2.10431422e+00],\n",
       "       [-1.08337461e+00, -3.77086307e-01],\n",
       "       [ 3.90939865e-01, -5.21144757e-01],\n",
       "       [ 1.63671293e-01,  1.01187833e+00],\n",
       "       [ 2.86562904e-01, -5.15740279e-01],\n",
       "       [-2.89068761e-01, -3.76607604e-01],\n",
       "       [ 6.63322741e-01,  2.05997922e-01],\n",
       "       [ 1.72030203e+00, -1.07781765e+00],\n",
       "       [-1.08463873e+00,  1.01176160e+00],\n",
       "       [ 3.90306352e+00,  9.28242772e+00],\n",
       "       [ 2.59522650e+00, -2.51237669e+00],\n",
       "       [ 5.43356670e-01, -3.27149113e+00],\n",
       "       [-8.58723801e-01, -1.99619489e+00],\n",
       "       [-1.02641973e+00,  1.45312245e-01],\n",
       "       [ 4.23707798e+00, -2.48704448e+00],\n",
       "       [ 3.73813711e+00, -2.41122535e+00],\n",
       "       [ 3.66284809e+00, -2.98456801e+00],\n",
       "       [ 7.15408494e-01,  8.15096008e-01],\n",
       "       [-6.52835267e-01,  1.91936381e-01],\n",
       "       [ 1.14621562e+00,  3.98203147e-01],\n",
       "       [ 9.66974159e-01, -3.98693490e-01],\n",
       "       [ 3.80717854e-01,  1.09922853e-01],\n",
       "       [ 4.69157440e+00,  9.25302058e+00],\n",
       "       [ 4.11250497e+00,  1.12653351e+01],\n",
       "       [ 4.55582113e+00,  1.04180032e+01],\n",
       "       [ 6.02059922e+00,  8.37651507e+00],\n",
       "       [ 6.02827843e+00,  8.65501826e+00],\n",
       "       [ 7.07306484e+00,  8.02884391e+00],\n",
       "       [-1.31067908e+00, -3.15712642e-01],\n",
       "       [ 1.14083840e+00, -7.75425816e-02],\n",
       "       [ 4.97672172e+00,  1.01739449e+01],\n",
       "       [ 2.51380315e+00, -2.84141567e+00],\n",
       "       [ 3.15773463e+00, -2.24510086e+00],\n",
       "       [ 3.56009624e+00, -1.25462386e+00],\n",
       "       [ 3.78289570e+00, -4.34807197e+00],\n",
       "       [ 2.86534459e+00, -2.46758913e+00],\n",
       "       [-2.35895537e-01,  5.83463488e-02],\n",
       "       [-1.81436932e-01,  4.46575975e-01],\n",
       "       [ 9.30382565e-01,  8.82084589e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
       "       2, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Grumpy Sunny Rainy Example\n",
    "\n",
    "https://www.youtube.com/watch?v=kqSzLo9fenk&t=431s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = hmm.GaussianHMM(n_components=3, covariance_type=\"diag\", init_params=\"cm\", params=\"cmt\")\n",
    "lr.startprob_ = np.array([0.67, 0.33])\n",
    "#                          S    R\n",
    "lr.transmat_ = np.array([[0.8, 0.4],  # S\n",
    "                         [0.2, 0.6]]) # R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[\"S\", \"S\", \"S\", \"S\", \"R\", \"R\", \"R\", \"S\", \"S\", \"S\", \"S\", \"R\", \"R\", \"S\", \"S\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='full', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=2, n_iter=100, params='stmc',\n",
       "      random_state=None, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel = hmm.GaussianHMM(n_components=2, covariance_type=\"full\", n_iter=100)\n",
    "remodel\n",
    "# remodel.fit(X)\n",
    "#Z2 = remodel.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock price prediction using Hidden Markov Model\n",
    "https://rubikscode.net/2018/10/29/stock-price-prediction-using-hidden-markov-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "DATA_DIR = \"/home/tales/dev/stock_data/data/\"\n",
    "\n",
    "class StockPredictor(object):\n",
    "    def __init__(self, company, n_latency_days=10, n_hidden_states=4):\n",
    "        self._init_logger()\n",
    " \n",
    "        self.company = company\n",
    "        self.n_latency_days = n_latency_days\n",
    "\n",
    "        self.hmm = GaussianHMM(n_components=n_hidden_states)\n",
    "        \n",
    "        self.data = pd.read_csv(\n",
    "            DATA_DIR + '/company_data/{company}.csv'.format(company=self.company))\n",
    "        \n",
    " \n",
    "    def _init_logger(self):\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self._logger.addHandler(handler)\n",
    "        self._logger.setLevel(logging.DEBUG)\n",
    " \n",
    "    @staticmethod\n",
    "    def _extract_features(data):\n",
    "        open_price = np.array(data['open'])\n",
    "        close_price = np.array(data['close'])\n",
    "        high_price = np.array(data['high'])\n",
    "        low_price = np.array(data['low'])\n",
    " \n",
    "        # Compute the fraction change in close, high and low prices\n",
    "        # which would be used a feature\n",
    "        frac_change = (close_price - open_price) / open_price\n",
    "        frac_high = (high_price - open_price) / open_price\n",
    "        frac_low = (open_price - low_price) / open_price\n",
    " \n",
    "        return np.column_stack((frac_change, frac_high, frac_low))\n",
    "\n",
    "    def _split_train_test_data(self, test_size):\n",
    "        data = pd.read_csv(\n",
    "            DATA_DIR + '/company_data/{company}.csv'.format(company=self.company))\n",
    "        _train_data, test_data = train_test_split(\n",
    "            data, test_size=test_size, shuffle=False)\n",
    " \n",
    "        self._train_data = _train_data\n",
    "        self._test_data = test_data\n",
    "\n",
    "    def fit(self):\n",
    "        self._logger.info('>>> Extracting Features')\n",
    "        feature_vector = StockPredictor._extract_features(self.data)\n",
    "        self._logger.info('Features extraction Completed <<<')\n",
    " \n",
    "        self.hmm.fit(feature_vector)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/tales/dev/stock_data/data//company_data/GOOGL.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-25b29a927a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predictor for GOOGL stocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstock_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GOOGL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstock_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5aeae896166c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, company, n_latency_days, n_hidden_states)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         self.data = pd.read_csv(\n\u001b[0;32m---> 18\u001b[0;31m             DATA_DIR + '/company_data/{company}.csv'.format(company=self.company))\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/tales/dev/stock_data/data//company_data/GOOGL.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Predictor for GOOGL stocks\n",
    "stock_predictor = StockPredictor(company='GOOGL')\n",
    "stock_predictor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains with Python\n",
    "\n",
    "https://medium.com/@__amol__/markov-chains-with-python-1109663f3678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "class MarkovChain(object):\n",
    "    \n",
    "    def __init__(self, transition_prob):\n",
    "        \"\"\"\n",
    "        Initialize the MarkovChain instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_prob: dict\n",
    "            A dict object representing the transition \n",
    "            probabilities in Markov Chain. \n",
    "            Should be of the form: \n",
    "                {'state1': {'state1': 0.1, 'state2': 0.4}, \n",
    "                 'state2': {...}}\n",
    "        \"\"\"\n",
    "        self.transition_prob = transition_prob\n",
    "        self.states = list(transition_prob.keys())\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        \"\"\"\n",
    "        Returns the state of the random variable at the next time \n",
    "        instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The current state of the system.\n",
    "        \"\"\"\n",
    "        return np.random.choice(\n",
    "            self.states, \n",
    "            p=[self.transition_prob[current_state][next_state] \n",
    "               for next_state in self.states]\n",
    "        )\n",
    " \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        \"\"\"\n",
    "        Generates the next states of the system.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The state of the current random variable.\n",
    " \n",
    "        no: int\n",
    "            The number of future states to generate.\n",
    "        \"\"\"\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state)\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "                   'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny', 'Rainy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_chain = MarkovChain(transition_prob=transition_prob)\n",
    "weather_chain.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rainy'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_chain.next_state(current_state='Sunny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_chain.next_state(current_state='Rainy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = weather_chain.generate_states(current_state='Sunny', no=15)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[\"Sunny\", \"Sunny\", \"Sunny\", \"Sunny\", \"Rainy\", \"Rainy\", \"Rainy\", \"Sunny\", \"Sunny\", \"Sunny\", \"Sunny\", \"Rainy\", \"Rainy\", \"Sunny\", \"Sunny\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"Sunny\", \"Sunny\", \"Sunny\", \"Sunny\", \"Rainy\", \"Rainy\", \"Rainy\", \"Sunny\", \"Sunny\", \"Sunny\", \"Sunny\", \"Rainy\", \"Rainy\", \"Sunny\", \"Sunny\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/tales/dev/master/mdc_analysis/\")\n",
    "print(\"working dir\", os.getcwd())\n",
    "\n",
    "from src.dao import csv_dao\n",
    "from src.entity.stop_region import StopRegionGroup\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 6070\n",
    "sr_list = csv_dao.stop_region_sequence(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_regions_group = StopRegionGroup(sr_list, agglutinate_stop_regions=True)\n",
    "stop_regions_group.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_tags = stop_regions_group.sequence_stop_region_tags()\n",
    "print(len(sequence_tags))\n",
    "sequence_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_probabilities(sequence_states, round_proba=4):\n",
    "    trans_proba_df = pd.DataFrame()\n",
    "    \n",
    "    trans_proba_df[\"origin\"] = sequence_states[0:-1]\n",
    "    trans_proba_df[\"origin\"] = trans_proba_df[\"origin\"].astype(str)\n",
    "    \n",
    "    trans_proba_df[\"destination\"] = sequence_states[1:]\n",
    "    trans_proba_df[\"destination\"] = trans_proba_df[\"destination\"].astype(str)\n",
    "    \n",
    "    trans_proba_df[\"transition\"] = trans_proba_df[\"origin\"].astype(str) + \" > \" + trans_proba_df[\"destination\"].astype(str)\n",
    "    trans_proba_df = trans_proba_df.set_index(trans_proba_df[\"transition\"], drop=False)\n",
    "    \n",
    "    trans_freq_df = trans_proba_df[\"transition\"].value_counts().to_frame()\n",
    "    trans_freq_df = trans_freq_df.rename(index=str, columns={\"transition\": \"transition_freq\"})\n",
    "    \n",
    "    trans_proba_df = trans_proba_df.merge(trans_freq_df, left_index=True, right_index=True).reset_index(drop=True).drop_duplicates()\n",
    "    del trans_proba_df[\"transition\"]\n",
    "    \n",
    "    trans_proba_df[\"transition_freq\"] = trans_proba_df[\"transition_freq\"] / trans_proba_df[\"transition_freq\"].sum()\n",
    "    trans_proba_df[\"transition_freq\"] = trans_proba_df[\"transition_freq\"].round(round_proba)\n",
    "    \n",
    "    return trans_proba_df\n",
    "\n",
    "def to_dict(trans_proba_df):\n",
    "    #maybe using pandas pivot table improve time execution \n",
    "    trans_proba_dict = {}\n",
    "    trans_proba_df.apply(lambda row : add_value(row, trans_proba_dict), axis=1)\n",
    "    \n",
    "    return trans_proba_dict \n",
    "    \n",
    "def add_value(row, trans_proba_dict):\n",
    "    outter_key = row[\"origin\"]\n",
    "    inner_key = row[\"destination\"]\n",
    "    value = row[\"transition_freq\"]\n",
    "    \n",
    "    if not outter_key in trans_proba_dict.keys():\n",
    "        trans_proba_dict[outter_key] = {inner_key: value}\n",
    "    else:\n",
    "        trans_proba_dict[outter_key][inner_key] = value\n",
    "        \n",
    "    return trans_proba_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tp = transition_probabilities(sequence_tags.tolist())\n",
    "tp\n",
    "tp_dict = to_dict(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chain = MarkovChain(transition_prob=tp_dict)\n",
    "destination_chain.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
